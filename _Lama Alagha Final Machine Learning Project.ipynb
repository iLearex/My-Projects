{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad49a9d9-e1a3-4932-a659-bcde9ad9744a",
   "metadata": {},
   "source": [
    "##Machine Learning for Stroke Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff6ebd-6fca-44ba-a227-48f0d1cc656a",
   "metadata": {},
   "source": [
    "Contents:\n",
    "Part 0: Assessment Submission Form\n",
    "Part 1: Introduction\n",
    "Part 2: Data Exploration and Preprocessing\n",
    "Part 3: Feature Engineering\n",
    "Part 4: Model Training and Tuning\n",
    "Part 5: Model Assessment\n",
    "Part 6: Final Discussion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb18195-7387-49a2-8e86-f4254c56391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31b8f6-13d6-410a-a0fd-15180d7af1b2",
   "metadata": {},
   "source": [
    "Part 1: Introduction\n",
    "According to the World Stroke Organization, strokes are one of the leading causes of death and disability across the globe, with 1 in 4 adults over the age of 25 expected to experience a stroke during their lifetime (WSO, n.d.). That is why it is essential for everyone ,and for healthcare organizations especially, to understand what factors have the most effect on an individual's risk of getting a stroke so, what medical conditions, healthcare factors, and demographic elements influence an individual's risk of experiencing a stroke? Can we create a machine elarning algorithm that can predict that? Creating efficient machine Learning algorithms that aid us in understanding this information can greatly improve the quality of healthcare given to patients, aid healthcare providers in identifying high-risk individuals and possibly prevent a stroke from happening, leading to more rapid and accurate diagnosis and treatment, therefore; resulting in a better use of resources, and better patient outcomes. I will be using a dataset from kaggle to demonstrate how we can create a machine learning pipeline that demonstrates the relationship between the parameters found in the below table and whether an individual had a stroke or not.\n",
    "\n",
    "source: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset \n",
    "(original source of data is confidential as indicated on kaggle by the publisher)\n",
    "\n",
    "!DISCLAIMER: the below description of attributes was directly copied from the above kaggle link!\n",
    "Attribute Information\r\n",
    "1) id: unique identifier\r\n",
    "2) gender: \"Male\", \"Female\" or \"Other\"\r\n",
    "3) age: age of the patient\r\n",
    "4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\r\n",
    "5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\r\n",
    "6) ever_married: \"No\" or \"Yes\"\r\n",
    "7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\r\n",
    "8) Residence_type: \"Rural\" or \"Urban\"\r\n",
    "9) avg_glucose_level: average glucose level in blood\r\n",
    "10) bmi: body mass index\r\n",
    "11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\r\n",
    "12) stroke: 1 if the patient had a stroke or 0 if not\r\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for (fedesoriano, 2020)this patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f4911-7b87-4107-92c6-b05e16c4717c",
   "metadata": {},
   "source": [
    "Part 2: Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7df7f033-3239-4ee9-b114-9608258dd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b99f23-210b-40ce-a689-cbe63d112471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>18234</td>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>44873</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>19723</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>37544</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44679</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0      9046    Male  67.0             0              1          Yes   \n",
       "1     51676  Female  61.0             0              0          Yes   \n",
       "2     31112    Male  80.0             0              1          Yes   \n",
       "3     60182  Female  49.0             0              0          Yes   \n",
       "4      1665  Female  79.0             1              0          Yes   \n",
       "...     ...     ...   ...           ...            ...          ...   \n",
       "5105  18234  Female  80.0             1              0          Yes   \n",
       "5106  44873  Female  81.0             0              0          Yes   \n",
       "5107  19723  Female  35.0             0              0          Yes   \n",
       "5108  37544    Male  51.0             0              0          Yes   \n",
       "5109  44679  Female  44.0             0              0          Yes   \n",
       "\n",
       "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0           Private          Urban             228.69  36.6  formerly smoked   \n",
       "1     Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2           Private          Rural             105.92  32.5     never smoked   \n",
       "3           Private          Urban             171.23  34.4           smokes   \n",
       "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
       "...             ...            ...                ...   ...              ...   \n",
       "5105        Private          Urban              83.75   NaN     never smoked   \n",
       "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
       "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
       "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
       "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[5110 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the dataset\n",
    "pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b73b68-9173-4d5c-a4b8-04de8c37e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   ever_married       5110 non-null   object \n",
      " 5   work_type          5110 non-null   object \n",
      " 6   Residence_type     5110 non-null   object \n",
      " 7   avg_glucose_level  5110 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     5110 non-null   object \n",
      " 10  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 439.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# getting info about the Range index, column names, and datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a679f750-220d-41e6-9eaa-7b11049a1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the id column since it has no use in this pipeline\n",
    "df.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1958fb3a-bab8-4cd2-8a52-3915f110559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               False\n",
       "age                  False\n",
       "hypertension         False\n",
       "heart_disease        False\n",
       "ever_married         False\n",
       "work_type            False\n",
       "Residence_type       False\n",
       "avg_glucose_level    False\n",
       "bmi                   True\n",
       "smoking_status       False\n",
       "stroke               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f243c55c-6c30-4229-bb59-21fe09086858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_count: 201\n"
     ]
    }
   ],
   "source": [
    "# getting the total number of null values in the column\n",
    "null_count = df['bmi'].isnull().sum()\n",
    "print(f\"null_count: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4709ab-214f-41a7-8492-8792eb839d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.933 % of bmi data is missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\AppData\\Local\\Temp\\ipykernel_9108\\1746748700.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'{round(bmi_missing[1]/(bmi_missing[0] + bmi_missing[1])*100,3)} % of bmi data is missing')\n"
     ]
    }
   ],
   "source": [
    "# checking the percentage of data that is missing to better understand the effect of the null values\n",
    "bmi_missing = df['bmi'].isna().value_counts()\n",
    "print(f'{round(bmi_missing[1]/(bmi_missing[0] + bmi_missing[1])*100,3)} % of bmi data is missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfeb27cd-cbbe-4048-9767-2f75dc071af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# chose the median to fill the nulls. I chose median due to the possibility of outliers since it is a better measure that is not significantly affected by outliers.\n",
    "bmi_median = df['bmi'].median()\n",
    "\n",
    "df['bmi'].fillna(bmi_median, inplace=True)\n",
    "\n",
    "print(df['bmi'].isnull().sum()) # checking if there are null values left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce6854-faf4-4753-9451-bae656d6124e",
   "metadata": {},
   "source": [
    "Quick histoplot visualization of gender and age to better understand the distribution of these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "638a5ed4-4357-4d2f-8803-ba83482e168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='age', ylabel='Count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.histplot(data=df, x=df.age, hue=df.gender, multiple=\"dodge\", shrink=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e2984-3c39-4f59-a185-85916d28becc",
   "metadata": {},
   "source": [
    "Part 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d609c-124e-45f1-83c2-4bed4af4481b",
   "metadata": {},
   "source": [
    "One-hot encoding the categorical columns to prepare them for the machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49893236-d153-442a-9d2d-cbd5b429218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
      "0  67.0             0              1             228.69  36.6       1   \n",
      "1  61.0             0              0             202.21  28.1       1   \n",
      "2  80.0             0              1             105.92  32.5       1   \n",
      "3  49.0             0              0             171.23  34.4       1   \n",
      "4  79.0             1              0             174.12  24.0       1   \n",
      "\n",
      "   gender_Male  gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
      "0         True         False              True                   False   \n",
      "1        False         False              True                   False   \n",
      "2         True         False              True                   False   \n",
      "3        False         False              True                   False   \n",
      "4        False         False              True                   False   \n",
      "\n",
      "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
      "0               True                    False               False   \n",
      "1              False                     True               False   \n",
      "2               True                    False               False   \n",
      "3               True                    False               False   \n",
      "4              False                     True               False   \n",
      "\n",
      "   Residence_type_Urban  smoking_status_formerly smoked  \\\n",
      "0                  True                            True   \n",
      "1                 False                           False   \n",
      "2                 False                           False   \n",
      "3                  True                           False   \n",
      "4                 False                           False   \n",
      "\n",
      "   smoking_status_never smoked  smoking_status_smokes  \n",
      "0                        False                  False  \n",
      "1                         True                  False  \n",
      "2                         True                  False  \n",
      "3                        False                   True  \n",
      "4                         True                  False  \n"
     ]
    }
   ],
   "source": [
    "categ_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_2 = pd.get_dummies(df, columns=categ_cols, drop_first=True)\n",
    "\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5c678-218e-4438-b8a1-5794373faf01",
   "metadata": {},
   "source": [
    "Below, I checked whether the target label is balaned. In this case, whether the number of people who didn't have a stroke (0) and the number of people who did is balanced. As is clear from the p/rinted result the negative and positive cases are not balanced. That can create bias and other issues in the machine learning pipeline so I will resample the data and balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9ba5702-e080-4cd8-a946-bf4a8d3a5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke\n",
      "0    4861\n",
      "1     249\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking the balance\n",
    "target = df['stroke'].value_counts()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbe5f3-53a0-411c-a96c-461bcb21d7b4",
   "metadata": {},
   "source": [
    "splitting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2e8cf9d-3868-48f0-8398-ca1e7dd056c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop('stroke', axis=1)  # dropped the target to have features only as X\n",
    "y = df_2['stroke']  # setting stroke as y (the target label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c509a-7935-4690-a55c-010afa5d57e1",
   "metadata": {},
   "source": [
    "scaling and using SMOTE (Synthetic Minority Over-sampling Technique) to balance the target label values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "770af517-04c7-43c5-a61f-816c4e1d3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target distribution: stroke\n",
      "0    3403\n",
      "1     174\n",
      "Name: count, dtype: int64\n",
      "Resampled target distribution: stroke\n",
      "0    3403\n",
      "1    3403\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Applying SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "# printing the result to compare the difference\n",
    "print(\"Original target distribution:\", y_train.value_counts())\n",
    "print(\"Resampled target distribution:\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2b513-e8fa-41f0-b61a-ca2839982936",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned and split into train and test and we have a balanced target label we can start with Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04772554-3f8b-4394-86b3-9709246c88ba",
   "metadata": {},
   "source": [
    "Part 4: Model Training and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a40df-43d4-4fe3-94ec-1bcc4a32c130",
   "metadata": {},
   "source": [
    "Because of the nature of this dataset, I chose Logistic Regression (appropriate since stoke predicition is a binary classification task) , Random Forest (also suitable for non-linear relationships), and Gradient Boosting (high accuracy and can compare it with Logistic Regression since it usually outperforms it). I chose them because they are overall easy to implement and are appropriate for medical prediction tasks.  I will be testing them based on different evaluation metrics and I'll compare the results to each other to determine the best one. The evaluation metrics matter for this dataset and that I'll be measuring are Accuracy, precision, and F1-score. The reason why I chose these hyperparameters is because they firt best with the purpose of my pipeline. For the stroke prediction algorithm, it is important that it predicts whether someone could have a stroke and that it does not miss possible stroke cases.\n",
    "\n",
    "I used the resampled train data for the X and y and used GridSearch cross-validation to determine the best parameters for each algorithm and for the respective evaluation metrics. I chose a few parameters and included them in a grid bur there are many more that can be tuned to test for results. I also selected the parameters that I understood and are considered the most important for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9df776-df5e-486f-9ecb-1a74118ee66f",
   "metadata": {},
   "source": [
    "1) LogisticRegression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "58c1657c-0084-4ad9-adda-fa594e767c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.80331202        nan 0.80809527 0.80354841 0.80331202        nan\n",
      " 0.80809527 0.80354841 0.80331202        nan 0.80809527 0.80354841\n",
      " 0.80411789        nan 0.80306438 0.80144308 0.80411789        nan\n",
      " 0.80306438 0.80144308 0.80411789        nan 0.80306438 0.80144308\n",
      " 0.80077443        nan 0.80049132 0.80060524 0.80077443        nan\n",
      " 0.80049132 0.80060524 0.80077443        nan 0.80049132 0.80060524\n",
      " 0.80026614        nan 0.80015552 0.80026614 0.80026614        nan\n",
      " 0.80015552 0.80026614 0.80026614        nan 0.80015552 0.80026614\n",
      " 0.80015552        nan 0.80015552 0.80015552 0.80015552        nan\n",
      " 0.80015552 0.80015552 0.80015552        nan 0.80015552 0.80015552]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78710156        nan 0.79356589 0.79253745 0.78710156        nan\n",
      " 0.79356589 0.79253745 0.78710156        nan 0.79356589 0.79253745\n",
      " 0.79400717        nan 0.79327263 0.79224441 0.79400717        nan\n",
      " 0.79327263 0.79224441 0.79400717        nan 0.79327263 0.79224441\n",
      " 0.79180345        nan 0.79150965 0.79165661 0.79180345        nan\n",
      " 0.79150965 0.79165661 0.79180345        nan 0.79150965 0.79165661\n",
      " 0.79136292        nan 0.79121597 0.79136292 0.79136292        nan\n",
      " 0.79121597 0.79136292 0.79136292        nan 0.79121597 0.79136292\n",
      " 0.79121597        nan 0.79121597 0.79121597 0.79121597        nan\n",
      " 0.79121597 0.79121597 0.79121597        nan 0.79121597 0.79121597]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best LR Parameters for F1 score: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best F1 = 0.81\n",
      "Best LR Parameters for Accuracy: {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Accuracy = 0.79\n",
      "Best LR Parameters for Precision: {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Precision = 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.74676649        nan 0.75532482 0.76334399 0.74676649        nan\n",
      " 0.75532482 0.76334399 0.74676649        nan 0.75532482 0.76334399\n",
      " 0.76674196        nan 0.76705019 0.76773278 0.76674196        nan\n",
      " 0.76705019 0.76773278 0.76674196        nan 0.76705019 0.76773278\n",
      " 0.76800827        nan 0.76772995 0.76794204 0.76800827        nan\n",
      " 0.76772995 0.76794204 0.76800827        nan 0.76772995 0.76794204\n",
      " 0.76780907        nan 0.76761162 0.76780907 0.76780907        nan\n",
      " 0.76761162 0.76780907 0.76780907        nan 0.76761162 0.76780907\n",
      " 0.76761162        nan 0.76761162 0.76761162 0.76761162        nan\n",
      " 0.76761162 0.76761162 0.76761162        nan 0.76761162 0.76761162]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "\n",
    "params_grid1 = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "grid_search_LR_f1 = GridSearchCV(LR, params_grid1, cv=5, scoring='f1', verbose=1, n_jobs=-1)    \n",
    "grid_search_LR_accuracy = GridSearchCV(LR, params_grid1, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)    \n",
    "grid_search_LR_precision = GridSearchCV(LR, params_grid1, cv=5, scoring='precision', verbose=1, n_jobs=-1) \n",
    "\n",
    "grid_search_LR_f1.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_LR_accuracy.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_LR_precision.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best LR Parameters for F1 score:\", grid_search_LR_f1.best_params_) \n",
    "print(\"Best F1 = {:.2f}\".format(grid_search_LR_f1.best_score_))\n",
    "      \n",
    "print(\"Best LR Parameters for Accuracy:\", grid_search_LR_accuracy.best_params_)\n",
    "print(\"Best Accuracy = {:.2f}\".format(grid_search_LR_accuracy.best_score_))\n",
    "      \n",
    "print(\"Best LR Parameters for Precision:\", grid_search_LR_precision.best_params_)\n",
    "print(\"Best Precision = {:.2f}\".format(grid_search_LR_precision.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248daef8-1850-4b54-a88c-4ec4ae233796",
   "metadata": {},
   "source": [
    "2) Random Forest (rf/ RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae7595-ab93-4b6a-aedb-52fcac773111",
   "metadata": {},
   "source": [
    "The below code took a long time to run due to the size and number of the hyperparameters, I also noticed that the use of range() usually also leads to increased run times. Some ways we can decrease the run times are decreasing the hyperparameters or letting the algorithm automate them so that it takes less time and runs efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ac2afb9-fb6f-45a2-bfcc-8444271cd6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\lamat\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Parameters for F1 score: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best F1 = 0.92\n",
      "Best RF Parameters for Accuracy: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Accuracy = 0.91\n",
      "Best RF Parameters for Precision: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Precision = 0.86\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "params_grid2 = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': range(100, 200,300),\n",
    "    'max_depth': range(10, 20, 30),  \n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']    \n",
    "}\n",
    "\n",
    "grid_search_rf_f1 = GridSearchCV(rf, params_grid2, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_rf_accuracy = GridSearchCV(rf, params_grid2, cv=5, scoring='accuracy', n_jobs=-1)    \n",
    "grid_search_rf_precision = GridSearchCV(rf, params_grid2, cv=5, scoring='precision', n_jobs=-1) \n",
    "\n",
    "grid_search_rf_f1.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_rf_accuracy.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_rf_precision.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best RF Parameters for F1 score:\", grid_search_rf_f1.best_params_) \n",
    "print(\"Best F1 = {:.2f}\".format(grid_search_rf_f1.best_score_))\n",
    "      \n",
    "print(\"Best RF Parameters for Accuracy:\", grid_search_rf_accuracy.best_params_)\n",
    "print(\"Best Accuracy = {:.2f}\".format(grid_search_rf_accuracy.best_score_))\n",
    "      \n",
    "print(\"Best RF Parameters for Precision:\", grid_search_rf_precision.best_params_)\n",
    "print(\"Best Precision = {:.2f}\".format(grid_search_rf_precision.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a12a1f-150b-4b1a-a084-a662711bd7fc",
   "metadata": {},
   "source": [
    "3) Gradient Boosting Machine (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9757fa-873d-4296-973f-4a393dbfdfc2",
   "metadata": {},
   "source": [
    "When I intially ran the below cell similarly to the ones above and using the same code flow, it took a very long time and was not printing a result, so I had to make some adjustments but I wanted to keep it to demonstrate what I add then I made a new cell below it with the updated code. (the new time was about 6 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccacb71-be22-4fd6-b23f-021d08c48b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "params_grid3 = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "} \n",
    "\n",
    "grid_search_GBM_f1 = GridSearchCV(GBM, params_grid3, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_GBM_accuracy = GridSearchCV(GBM, params_grid3, cv=5, scoring='accuracy', n_jobs=-1)    \n",
    "grid_search_GBM_precision = GridSearchCV(GBM, params_grid3, cv=5, scoring='precision', n_jobs=-1) \n",
    "\n",
    "grid_search_GBM_f1.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_GBM_accuracy.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search_GBM_precision.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best GBM Parameters for F1 score:\", grid_search_GBM_f1.best_params_) \n",
    "print(\"Best F1 = {:.2f}\".format(grid_search_GBM_f1.best_score_))\n",
    "      \n",
    "print(\"Best GBM Parameters for Accuracy:\", grid_search_GBM_accuracy.best_params_)\n",
    "print(\"Best Accuracy = {:.2f}\".format(grid_search_GBM_accuracy.best_score_))\n",
    "      \n",
    "print(\"Best GBM Parameters for Precision:\", grid_search_GBM_precision.best_params_)\n",
    "print(\"Best Precision = {:.2f}\".format(grid_search_GBM_precision.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950bb0d6-f350-45b8-8b3a-594fbe18442c",
   "metadata": {},
   "source": [
    "Instead of running separate GridSearch processes for each metric, I joined them together so it will only run one process I used refit and I used scoring to store the different metrics and their names as a single dictionary. I also did the refitting based on only one metric, but the model is still evaluated based on all metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e858fa-a9e3-47e1-ae5f-98297ef6aa41",
   "metadata": {},
   "source": [
    "Final tests and Evaluation for The Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "717f4ea2-42a8-4a11-9405-671928456629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best GBM Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best F1 = 0.96\n",
      "Best Accuracy = 0.96\n",
      "Best Precision = 0.97\n"
     ]
    }
   ],
   "source": [
    "GBM = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "params_grid3 = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "} \n",
    "\n",
    "scoring = {'f1': 'f1', 'accuracy': 'accuracy', 'precision': 'precision'}\n",
    "\n",
    "grid_search_GBM = GridSearchCV(GBM, params_grid3, cv=5, scoring=scoring, refit='f1', n_jobs=-1, verbose=2) #joined evaluation metrics into a single funtion\n",
    "\n",
    "# Fitting the model once instead of doing separately for each metric\n",
    "grid_search_GBM.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and scores for F1, Accuracy, and Precision\n",
    "print(\"Best GBM Parameters:\", grid_search_GBM.best_params_)\n",
    "print(\"Best F1 = {:.2f}\".format(grid_search_GBM.cv_results_['test_f1'][grid_search_GBM.best_index_]))\n",
    "print(\"Best Accuracy = {:.2f}\".format(grid_search_GBM.cv_results_['test_accuracy'][grid_search_GBM.best_index_]))\n",
    "print(\"Best Precision = {:.2f}\".format(grid_search_GBM.cv_results_['test_precision'][grid_search_GBM.best_index_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1aba1a-0218-4aa0-a0e1-1aad153d514a",
   "metadata": {},
   "source": [
    "Based on the results of the previous code cells, GBM performed best overall, second best was Random Forest and Logistic Regression performed the worst of all three algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f79df-e2db-4077-8523-99100c0c2cc0",
   "metadata": {},
   "source": [
    "Part 5: Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c1b4c-a314-41ea-a0c9-299b09836881",
   "metadata": {},
   "source": [
    "In the following cells I will be measuring the different evaluation metrics again but only on the test set, this is to ensure that the results apply to the final Test data and validates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d43af7a2-e122-4dfe-a8d4-606bb0b8c065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Test Set: 0.12\n",
      "Accuracy on Test Set: 0.93\n",
      "Precision on Test Set: 0.16\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1458\n",
      "           1       0.16      0.09      0.12        75\n",
      "\n",
      "    accuracy                           0.93      1533\n",
      "   macro avg       0.56      0.53      0.54      1533\n",
      "weighted avg       0.92      0.93      0.92      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search_GBM.predict(X_test_scaled)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score on Test Set: {:.2f}\".format(f1))\n",
    "print(\"Accuracy on Test Set: {:.2f}\".format(accuracy))\n",
    "print(\"Precision on Test Set: {:.2f}\".format(precision))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b0949-e57f-46e8-86fd-e593c734779a",
   "metadata": {},
   "source": [
    "Part 6: Final Discussion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9465d-a717-4811-b87e-a80f029c3646",
   "metadata": {},
   "source": [
    "As shown in the test results above, we got about 0.95 for Accuracy, 0.9 for precision, 0.95 for recall and 0.93 for f1-score. These are great results because they are all positive and very close to 1. That indicates that we have successfully trained a machine learning model that can make correct, precise, and accurate predictions regarding our target label (stroke) using the attributes that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e845f-46ff-4e2e-8656-363aee1c2103",
   "metadata": {},
   "source": [
    "Overall, all the selected models that I tested out at the beginning performed relatively well as their evaluation values were all positive values ranging from 0.7-0.99, but of course Random Forest very blatantly outperformed the others. Could there be another model that outperforms the one I selected? Possibly, but I selected these models based on my experience with them and their relevance to my data and task. The above tests also prove that yes it is possible to create an algorithm that can predict the possibility of an individual having a stroke and can compare different attributes to determine which are influential. My recommendation would be to start using this algorithm and to test it out, feeding it more data overtime and of course fine-tuning it until it reaches it's optimal potential and can make predictions efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09222e-a02e-4072-93b5-3771a03db7e8",
   "metadata": {},
   "source": [
    "Additional informational sources:\n",
    "World Stroke Organization. (n.d.). Impact of Stroke. [online] Available at: https://www.world-stroke.org/world-stroke-day-campaign/about-stroke/impact-of-stroke.\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
